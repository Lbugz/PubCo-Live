import * as cron from "node-cron";
import type { IStorage } from "./storage";
import { getAuthStatus } from "./auth-monitor";

/**
 * Automated Scraping Scheduler
 * 
 * Manages scheduled jobs for automatic playlist scraping.
 * All jobs are controlled by the ENABLE_AUTO_SCRAPE environment variable.
 * 
 * Cron format: minute hour day month weekday
 * 
 * Examples:
 *   '0 9 * * 5' = Every Friday at 9:00 AM
 *   '0 0 * * 0' = Every Sunday at midnight
 *   '0 /6 * * *' = Every 6 hours (note: use asterisk/6 without spaces)
 */

interface ScheduledJob {
  name: string;
  schedule: string;
  description: string;
  task: () => Promise<void>;
  cronJob?: ReturnType<typeof cron.schedule>;
}

const scheduledJobs: ScheduledJob[] = [];

/**
 * Check if automatic scraping is enabled
 */
function isAutoScrapeEnabled(): boolean {
  const enabled = process.env.ENABLE_AUTO_SCRAPE === 'true';
  return enabled;
}

/**
 * Register a scheduled job
 */
export function registerJob(
  name: string,
  schedule: string,
  description: string,
  task: () => Promise<void>
) {
  const job: ScheduledJob = {
    name,
    schedule,
    description,
    task,
  };
  
  scheduledJobs.push(job);
  console.log(`üìÖ Registered job: ${name}`);
  console.log(`   Schedule: ${schedule} (${description})`);
}

/**
 * Start all registered scheduled jobs
 */
export function startScheduler() {
  const enabled = isAutoScrapeEnabled();
  
  console.log("\n" + "=".repeat(70));
  console.log("‚è∞ SCHEDULER INITIALIZATION");
  console.log("=".repeat(70));
  console.log(`Status: ${enabled ? '‚úÖ ENABLED' : '‚è∏Ô∏è  DISABLED'}`);
  console.log(`Environment: ENABLE_AUTO_SCRAPE=${process.env.ENABLE_AUTO_SCRAPE || 'not set'}`);
  console.log(`Registered Jobs: ${scheduledJobs.length}`);
  
  if (!enabled) {
    console.log("\nüí° To enable automatic scraping:");
    console.log("   1. Add a Replit Secret: ENABLE_AUTO_SCRAPE = true");
    console.log("   2. Restart the application");
    console.log("=".repeat(70) + "\n");
    return;
  }
  
  // Check auth status before starting
  const authStatus = getAuthStatus();
  if (!authStatus.lastSuccessfulAuth) {
    console.warn("\n‚ö†Ô∏è  WARNING: No successful authentication detected!");
    console.warn("   Scheduled jobs may fail without valid Spotify cookies.");
    console.warn("   Run: node spotify-auth-export.js");
  }
  
  console.log("\nüöÄ Starting scheduled jobs:");
  
  for (const job of scheduledJobs) {
    // Create and start the cron job
    job.cronJob = cron.schedule(job.schedule, async () => {
      console.log(`\n‚è∞ [${new Date().toISOString()}] Running: ${job.name}`);
      try {
        await job.task();
        console.log(`‚úÖ [${new Date().toISOString()}] Completed: ${job.name}`);
      } catch (error) {
        console.error(`‚ùå [${new Date().toISOString()}] Failed: ${job.name}`);
        console.error(error);
      }
    });
    
    console.log(`   ‚úì ${job.name}`);
    console.log(`     Schedule: ${job.schedule} (${job.description})`);
  }
  
  console.log("\n" + "=".repeat(70) + "\n");
}

/**
 * Stop all scheduled jobs
 */
export function stopScheduler() {
  console.log("‚èπÔ∏è  Stopping scheduler...");
  
  for (const job of scheduledJobs) {
    if (job.cronJob) {
      job.cronJob.stop();
      console.log(`   Stopped: ${job.name}`);
    }
  }
  
  console.log("‚úÖ Scheduler stopped");
}

/**
 * Get status of all scheduled jobs
 */
export function getSchedulerStatus() {
  return {
    enabled: isAutoScrapeEnabled(),
    jobs: scheduledJobs.map(job => ({
      name: job.name,
      schedule: job.schedule,
      description: job.description,
      running: job.cronJob ? true : false,
    })),
  };
}

/**
 * Initialize the scheduler with storage
 * This is called from the main server file
 */
export async function initializeScheduler(storage: IStorage) {
  console.log("üîß Initializing scheduler with storage...");
  
  // Register Fresh Finds weekly scrape job
  registerJob(
    "Fresh Finds Weekly Update",
    "0 9 * * 5", // Every Friday at 9:00 AM
    "Fridays at 9:00 AM",
    async () => {
      console.log("üéµ Starting Fresh Finds weekly scrape...");
      
      // Fresh Finds playlist URL
      const FRESH_FINDS_URL = "https://open.spotify.com/playlist/37i9dQZF1DX4dyzvuaRJ0n";
      
      try {
        // Try microservice first, fall back to direct scraping
        let result;
        const microserviceUrl = process.env.SCRAPER_API_URL;
        
        if (microserviceUrl) {
          console.log("Using microservice for Fresh Finds scrape...");
          const response = await fetch(`${microserviceUrl}/scrape-playlist`, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ playlistUrl: FRESH_FINDS_URL }),
          });
          
          result = await response.json();
        } else {
          console.log("Microservice not available, using direct scraping...");
          const { scrapeSpotifyPlaylist } = await import("./scraper");
          result = await scrapeSpotifyPlaylist(FRESH_FINDS_URL);
        }
        
        if (result.success && result.tracks) {
          console.log(`‚úÖ Scraped ${result.tracks.length} tracks from Fresh Finds`);
          
          // Store tracks in database
          const weekId = `week-${new Date().toISOString().split('T')[0]}`;
          
          const tracksToInsert = result.tracks.map(track => ({
            week: weekId,
            playlistName: result.playlistName || "Fresh Finds",
            trackName: track.trackName,
            artistName: track.artistName,
            album: track.album,
            duration: track.duration,
            spotifyUrl: track.spotifyUrl,
            addedAt: new Date(),
          }));
          
          await storage.insertTracks(tracksToInsert);
          
          console.log(`‚úÖ Stored ${result.tracks.length} tracks in database`);
        } else {
          console.error("‚ùå Scrape failed:", result.error);
        }
      } catch (error) {
        console.error("‚ùå Fresh Finds scrape error:", error);
        throw error;
      }
    }
  );
  
  // Future jobs can be registered here:
  // - Other playlist updates
  // - Data enrichment jobs
  // - Cleanup/maintenance tasks
  
  // Start the scheduler (will only actually start if ENABLE_AUTO_SCRAPE=true)
  startScheduler();
}
