Perfect, 1sthexagram â€” here is the **full Background Job Queue architecture**, written as a **clean design document** you can hand directly to the agent **once you approve implementation**.

No changes will be made.
This is **architecture-only**, exactly as you requested.

---

# ğŸ”§ **BACKGROUND JOB QUEUE ARCHITECTURE (FINAL DESIGN)**

### *Production-ready, scalable, Puppeteer-safe, and fully compatible with MLC Phase 3*

---

# 1ï¸âƒ£ **Core Problem We Are Solving**

Your logs prove:

* Phase 2 scraping is now **functionally correct**
* Memory leaks + concurrency issues are **fixed**
* BUT running Puppeteer **inside an HTTP route** still causes:

  * Server restarts
  * OOM kills
  * Lost logs
  * Partial enrichments
  * No way to scale to 30, 50, 100, 500 tracks

### â— The ONLY correct architecture:

Move enrichment *off the request thread* into a **background job worker**.

---

# 2ï¸âƒ£ **High-Level Architecture Diagram**

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
User clicks â€œEnrichâ€ â†’  â”‚ POST /api/enrichment-jobs â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  Job Queue (JS)  â”‚
                           â”‚  jobs[], status  â”‚
                           â”‚  rate limiter    â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ Background Worker (Node) â”‚
                      â”‚  - Puppeteer (max 1)     â”‚
                      â”‚  - MLC API               â”‚
                      â”‚  - Chartmetric           â”‚
                      â”‚  - MusicBrainz           â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚ PostgreSQL (DB) â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  WebSocket Status Updates â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                UI shows live % done, enriched track results
```

---

# 3ï¸âƒ£ **TECH COMPONENTS**

### **A) Job Queue (in-memory first)**

Weâ€™ll start with a simple in-memory queue:

```ts
class JobQueue {
  jobs = [];
  workers = 1; // max concurrency
  isRunning = false;
}
```

Later you can swap this for BullMQ or Redis.

---

### **B) Background Worker**

A separate loop that:

* Pulls 1 job at a time
* Processes tasks sequentially
* Ensures **only 1 Chromium browser** runs at a time
* Publishes progress via WebSocket

This is the heart of the system.

---

### **C) Job Record Structure**

```ts
{
  id: 'uuid',
  type: 'enrich-playlist' | 'enrich-tracks',
  playlistId: string,
  trackIds: string[],
  status: 'queued' | 'running' | 'completed' | 'failed',
  progress: number,
  createdAt: Date,
  updatedAt: Date,
  logs: string[],
}
```

---

### **D) New API Endpoints (no implementation yet)**

#### **POST /api/enrichment-jobs**

Submit a new job:

```
{
  "playlistId": "...",
  "trackIds": ["...", "..."]
}
```

Response:

```
{ jobId: "abc123", status: "queued" }
```

---

#### **GET /api/enrichment-jobs/:jobId**

Return job status:

```
{
  "status": "running",
  "progress": 47,
  "logs": [...]
}
```

---

#### **WS: enrichment-progress**

Background worker pushes events:

```
{
  "jobId": "abc123",
  "progress": 62,
  "message": "Scraped credits for 10/16 tracks"
}
```

---

# 4ï¸âƒ£ **WORKER EXECUTION FLOW**

### **1. Acquire job**

```
job = queue.next()
job.status = "running"
```

---

### **2. For each track:**

#### **Tier 0: Spotify API ISRC Recovery**

* Always run with batch API helper
* Recovers missing ISRC
* Updates DB
* Updates progress

#### **Tier 1: Spotify Credits Scraping**

* Uses Puppeteer
* Concurrency = 1
* Selector-based waits (no networkidle2)
* Extracts:

  * writers
  * composers
  * producers
  * publishers
  * stream count

#### **Tier 2: MLC API**

* Uses your new MLC access
* ISRC-based lookup
* Returns:

  * publisherStatus
  * collectionShare
  * ipi
  * iswc
  * songCode

#### **Tier 3: MusicBrainz**

* Searches top 3 writers
* Stores external links
* Links artists to track

#### **Tier 4: Chartmetric Analytics**

* If `chartmetricId` exists
* Enrich track with:

  * streamingVelocity
  * moods
  * activities
  * composerName

#### **Update DB per track**

Guarantees no data loss.

---

# 5ï¸âƒ£ **ADVANCED BEHAVIOR**

### **A) Crash Protection**

If worker crashes:

* Job remains `failed`
* Partial data persists
* System auto-resets

### **B) Restart Safety**

When server restarts:

* Pending jobs reload
* Worker resumes queue

### **C) Batch Size**

Track processing chunked into:

* 5â€“10 tracks max
* Sequential processing to avoid OOM

---

# 6ï¸âƒ£ **BENEFITS**

### âœ” No more server crashes

### âœ” Unlimited scalability

### âœ” MLC integration becomes safe

### âœ” Works for 10 tracks or 10,000

### âœ” UI gets live enrichment progress

### âœ” Phase 2 scraping remains stable

### âœ” Fetch Data stays fast & lightweight

### âœ” Full enrichment pipeline becomes production-grade

---

# 7ï¸âƒ£ **THE CORRECT IMPLEMENTATION ORDER (SAFE)**

### **Step 1 â€” Build Job Queue skeleton**

(no Puppeteer yet)

### **Step 2 â€” Move Phase 2 scraping into job worker**

(1 browser at a time)

### **Step 3 â€” Add MLC API integration inside worker**

### **Step 4 â€” Add Chartmetric + MusicBrainz inside worker**

### **Step 5 â€” Connect Track â€œEnrich Dataâ€ button â†’ queue submit**

### **Step 6 â€” Add UI progress bar to playlist/track view**

### **Step 7 â€” Enable Auto-Enrich toggle per playlist**

---

# 8ï¸âƒ£ **WHAT THIS MEANS FOR YOU IMMEDIATELY**

Youâ€™re now ready to:

### âœ” integrate MLC

### âœ” get stable enrichment

### âœ” scale enrichment

### âœ” remove scraper crashes

### âœ” eventually do FULL AUTOMATION safely

Your platform will now behave like a real A&R intelligence engine.

---

# ğŸ”® READY TO IMPLEMENT WHEN YOU ARE

Just say:

**â€œApprove background job queue implementation â€” Begin Phase 1.â€**

And Iâ€™ll prepare the implementation task list for the agent.
